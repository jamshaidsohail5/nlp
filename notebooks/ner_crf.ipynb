{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition - Conditional Random Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/Data/repo/nlp\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "from algorithms.ner_crf import sent2features, sent2labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with gzip.open('datasets/ner/data.json.gz', mode='rt', encoding='utf-8') as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Thousands', 'NNS'], 'O'],\n",
       " [['of', 'IN'], 'O'],\n",
       " [['demonstrators', 'NNS'], 'O'],\n",
       " [['have', 'VBP'], 'O'],\n",
       " [['marched', 'VBN'], 'O'],\n",
       " [['through', 'IN'], 'O'],\n",
       " [['London', 'NNP'], 'B-geo'],\n",
       " [['to', 'TO'], 'O'],\n",
       " [['protest', 'VB'], 'O'],\n",
       " [['the', 'DT'], 'O'],\n",
       " [['war', 'NN'], 'O'],\n",
       " [['in', 'IN'], 'O'],\n",
       " [['Iraq', 'NNP'], 'B-geo'],\n",
       " [['and', 'CC'], 'O'],\n",
       " [['demand', 'VB'], 'O'],\n",
       " [['the', 'DT'], 'O'],\n",
       " [['withdrawal', 'NN'], 'O'],\n",
       " [['of', 'IN'], 'O'],\n",
       " [['British', 'JJ'], 'B-gpe'],\n",
       " [['troops', 'NNS'], 'O'],\n",
       " [['from', 'IN'], 'O'],\n",
       " [['that', 'DT'], 'O'],\n",
       " [['country', 'NN'], 'O'],\n",
       " [['.', '.'], 'O']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_texts = []\n",
    "\n",
    "for text in data:\n",
    "    temp = []\n",
    "    for word in text:\n",
    "        temp.append((word[0][0], word[1]))\n",
    "    labeled_texts.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'O'),\n",
       " ('of', 'O'),\n",
       " ('demonstrators', 'O'),\n",
       " ('have', 'O'),\n",
       " ('marched', 'O'),\n",
       " ('through', 'O'),\n",
       " ('London', 'B-geo'),\n",
       " ('to', 'O'),\n",
       " ('protest', 'O'),\n",
       " ('the', 'O'),\n",
       " ('war', 'O'),\n",
       " ('in', 'O'),\n",
       " ('Iraq', 'B-geo'),\n",
       " ('and', 'O'),\n",
       " ('demand', 'O'),\n",
       " ('the', 'O'),\n",
       " ('withdrawal', 'O'),\n",
       " ('of', 'O'),\n",
       " ('British', 'B-gpe'),\n",
       " ('troops', 'O'),\n",
       " ('from', 'O'),\n",
       " ('that', 'O'),\n",
       " ('country', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:word.lower()': 'marched',\n",
       " '-1:word.istitle()': False,\n",
       " '-1:word.isupper()': False,\n",
       " '-1:word.lower()': 'demonstrators',\n",
       " '-2:word.istitle()': False,\n",
       " '-2:word.isupper()': False,\n",
       " '-2:word.lower()': 'of',\n",
       " 'bias': 1.0,\n",
       " 'word.isdigit()': False,\n",
       " 'word.istitle()': False,\n",
       " 'word.isupper()': False,\n",
       " 'word.lower()': 'have',\n",
       " 'word_length': 4}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(labeled_texts[0])[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62010"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_length = len(labeled_texts)\n",
    "texts_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46507"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_share = .75\n",
    "train_size = int(texts_length * train_share)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "train_indices = np.random.choice(texts_length, size=train_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [sent2features(labeled_texts[i]) for i in train_indices]\n",
    "y_train = [sent2labels(labeled_texts[i]) for i in train_indices]\n",
    "\n",
    "X_test = [sent2features(labeled_texts[i]) for i in range(texts_length) if i not in train_indices]\n",
    "y_test = [sent2labels(labeled_texts[i]) for i in range(texts_length) if i not in train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 46507/46507 [00:09<00:00, 4985.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 183073\n",
      "Seconds required: 1.519\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 300\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=2.99  loss=1375912.83 active=181496 feature_norm=1.00\n",
      "Iter 2   time=1.52  loss=1321711.13 active=174592 feature_norm=0.94\n",
      "Iter 3   time=3.00  loss=1118300.38 active=171217 feature_norm=0.94\n",
      "Iter 4   time=1.50  loss=973376.08 active=169631 feature_norm=1.26\n",
      "Iter 5   time=3.04  loss=880417.44 active=170174 feature_norm=2.20\n",
      "Iter 6   time=3.10  loss=749928.65 active=171999 feature_norm=2.27\n",
      "Iter 7   time=1.53  loss=698928.58 active=172368 feature_norm=2.87\n",
      "Iter 8   time=3.06  loss=674832.37 active=182545 feature_norm=3.25\n",
      "Iter 9   time=1.53  loss=650271.99 active=182534 feature_norm=3.38\n",
      "Iter 10  time=1.54  loss=637491.63 active=181994 feature_norm=3.96\n",
      "Iter 11  time=1.53  loss=608261.48 active=182587 feature_norm=4.00\n",
      "Iter 12  time=1.53  loss=592801.45 active=182441 feature_norm=4.24\n",
      "Iter 13  time=1.52  loss=500807.94 active=160818 feature_norm=7.65\n",
      "Iter 14  time=1.55  loss=430179.46 active=166016 feature_norm=9.30\n",
      "Iter 15  time=1.56  loss=417672.81 active=164469 feature_norm=9.53\n",
      "Iter 16  time=1.53  loss=371114.07 active=151073 feature_norm=11.96\n",
      "Iter 17  time=1.53  loss=339329.66 active=151239 feature_norm=12.88\n",
      "Iter 18  time=1.53  loss=310006.19 active=149879 feature_norm=14.52\n",
      "Iter 19  time=1.56  loss=289530.35 active=148532 feature_norm=17.36\n",
      "Iter 20  time=1.52  loss=281385.55 active=149110 feature_norm=18.96\n",
      "Iter 21  time=1.52  loss=270362.18 active=148722 feature_norm=19.85\n",
      "Iter 22  time=1.51  loss=257902.92 active=146503 feature_norm=21.38\n",
      "Iter 23  time=1.51  loss=243087.78 active=145608 feature_norm=23.75\n",
      "Iter 24  time=1.51  loss=227417.66 active=144396 feature_norm=27.50\n",
      "Iter 25  time=1.51  loss=215170.18 active=144196 feature_norm=29.48\n",
      "Iter 26  time=1.51  loss=202453.75 active=141886 feature_norm=32.97\n",
      "Iter 27  time=3.00  loss=198466.91 active=138293 feature_norm=36.67\n",
      "Iter 28  time=1.51  loss=182887.41 active=139447 feature_norm=38.22\n",
      "Iter 29  time=1.51  loss=175093.81 active=137977 feature_norm=41.40\n",
      "Iter 30  time=1.51  loss=161961.24 active=131578 feature_norm=49.90\n",
      "Iter 31  time=1.51  loss=149110.68 active=129041 feature_norm=56.37\n",
      "Iter 32  time=1.51  loss=141562.61 active=125837 feature_norm=62.90\n",
      "Iter 33  time=1.51  loss=138458.55 active=125775 feature_norm=64.00\n",
      "Iter 34  time=1.51  loss=135386.55 active=124946 feature_norm=64.15\n",
      "Iter 35  time=1.51  loss=130144.95 active=121560 feature_norm=67.78\n",
      "Iter 36  time=1.51  loss=122897.29 active=120917 feature_norm=72.02\n",
      "Iter 37  time=1.51  loss=119358.22 active=118465 feature_norm=75.84\n",
      "Iter 38  time=1.51  loss=109865.07 active=114144 feature_norm=91.13\n",
      "Iter 39  time=3.01  loss=107678.95 active=114934 feature_norm=97.48\n",
      "Iter 40  time=1.51  loss=102885.58 active=115122 feature_norm=100.51\n",
      "Iter 41  time=1.51  loss=99727.05 active=113415 feature_norm=105.96\n",
      "Iter 42  time=1.51  loss=95378.99 active=112944 feature_norm=113.38\n",
      "Iter 43  time=1.50  loss=91772.80 active=111474 feature_norm=126.68\n",
      "Iter 44  time=1.51  loss=87019.57 active=113345 feature_norm=129.62\n",
      "Iter 45  time=1.51  loss=84814.46 active=112062 feature_norm=133.45\n",
      "Iter 46  time=1.51  loss=79696.76 active=109273 feature_norm=145.00\n",
      "Iter 47  time=1.51  loss=79434.78 active=108245 feature_norm=153.55\n",
      "Iter 48  time=1.51  loss=76099.49 active=108712 feature_norm=154.42\n",
      "Iter 49  time=1.51  loss=74698.21 active=108293 feature_norm=156.74\n",
      "Iter 50  time=1.52  loss=72143.63 active=106074 feature_norm=164.50\n",
      "Iter 51  time=4.53  loss=71948.76 active=105105 feature_norm=167.69\n",
      "Iter 52  time=1.52  loss=69406.55 active=105309 feature_norm=175.22\n",
      "Iter 53  time=1.51  loss=67804.67 active=103203 feature_norm=181.58\n",
      "Iter 54  time=1.51  loss=64726.22 active=99785 feature_norm=200.80\n",
      "Iter 55  time=3.01  loss=63746.00 active=99487 feature_norm=207.19\n",
      "Iter 56  time=1.51  loss=62272.93 active=99661 feature_norm=211.34\n",
      "Iter 57  time=1.51  loss=60920.10 active=98622 feature_norm=218.99\n",
      "Iter 58  time=1.51  loss=59078.40 active=96935 feature_norm=232.41\n",
      "Iter 59  time=3.01  loss=58266.19 active=96699 feature_norm=239.55\n",
      "Iter 60  time=1.51  loss=56960.23 active=96664 feature_norm=246.49\n",
      "Iter 61  time=1.51  loss=56110.29 active=96472 feature_norm=252.15\n",
      "Iter 62  time=1.51  loss=55094.71 active=95484 feature_norm=259.64\n",
      "Iter 63  time=3.00  loss=54830.01 active=94794 feature_norm=264.86\n",
      "Iter 64  time=1.51  loss=54128.86 active=94433 feature_norm=268.34\n",
      "Iter 65  time=1.51  loss=53712.40 active=94165 feature_norm=271.60\n",
      "Iter 66  time=1.51  loss=53183.58 active=92410 feature_norm=277.39\n",
      "Iter 67  time=1.51  loss=52801.35 active=91665 feature_norm=278.46\n",
      "Iter 68  time=1.51  loss=52565.74 active=91519 feature_norm=278.46\n",
      "Iter 69  time=1.51  loss=52132.46 active=89977 feature_norm=280.08\n",
      "Iter 70  time=1.51  loss=51787.08 active=89687 feature_norm=280.56\n",
      "Iter 71  time=1.51  loss=51405.12 active=88533 feature_norm=282.32\n",
      "Iter 72  time=1.51  loss=51068.33 active=87061 feature_norm=284.55\n",
      "Iter 73  time=1.51  loss=50741.23 active=85953 feature_norm=286.40\n",
      "Iter 74  time=1.51  loss=50493.54 active=85747 feature_norm=287.42\n",
      "Iter 75  time=1.50  loss=50230.31 active=85193 feature_norm=288.69\n",
      "Iter 76  time=3.01  loss=50134.36 active=84718 feature_norm=289.49\n",
      "Iter 77  time=1.51  loss=49883.96 active=84381 feature_norm=290.41\n",
      "Iter 78  time=1.51  loss=49728.07 active=84212 feature_norm=291.22\n",
      "Iter 79  time=1.51  loss=49565.09 active=83980 feature_norm=291.89\n",
      "Iter 80  time=1.51  loss=49358.73 active=83677 feature_norm=292.90\n",
      "Iter 81  time=1.51  loss=49187.40 active=83519 feature_norm=293.50\n",
      "Iter 82  time=1.51  loss=49026.56 active=83150 feature_norm=294.13\n",
      "Iter 83  time=1.51  loss=48881.10 active=82851 feature_norm=294.72\n",
      "Iter 84  time=1.51  loss=48755.35 active=82486 feature_norm=295.33\n",
      "Iter 85  time=1.51  loss=48631.75 active=82247 feature_norm=295.85\n",
      "Iter 86  time=1.51  loss=48522.83 active=81675 feature_norm=296.60\n",
      "Iter 87  time=1.51  loss=48418.86 active=81642 feature_norm=296.92\n",
      "Iter 88  time=1.51  loss=48321.55 active=81196 feature_norm=297.42\n",
      "Iter 89  time=4.51  loss=48312.31 active=81059 feature_norm=297.65\n",
      "Iter 90  time=1.51  loss=48204.66 active=81014 feature_norm=298.18\n",
      "Iter 91  time=1.51  loss=48138.89 active=80743 feature_norm=298.53\n",
      "Iter 92  time=1.50  loss=48057.29 active=80492 feature_norm=298.85\n",
      "Iter 93  time=1.51  loss=47977.29 active=80111 feature_norm=299.40\n",
      "Iter 94  time=1.51  loss=47908.28 active=79971 feature_norm=299.63\n",
      "Iter 95  time=1.51  loss=47848.55 active=79834 feature_norm=299.87\n",
      "Iter 96  time=1.51  loss=47775.55 active=79538 feature_norm=300.14\n",
      "Iter 97  time=1.51  loss=47715.51 active=79288 feature_norm=300.41\n",
      "Iter 98  time=1.51  loss=47660.12 active=79112 feature_norm=300.58\n",
      "Iter 99  time=1.51  loss=47611.92 active=78950 feature_norm=300.76\n",
      "Iter 100 time=1.51  loss=47557.13 active=78816 feature_norm=300.91\n",
      "Iter 101 time=1.51  loss=47501.24 active=78660 feature_norm=301.14\n",
      "Iter 102 time=1.51  loss=47456.09 active=78436 feature_norm=301.26\n",
      "Iter 103 time=1.51  loss=47421.53 active=78324 feature_norm=301.42\n",
      "Iter 104 time=1.51  loss=47376.97 active=78341 feature_norm=301.49\n",
      "Iter 105 time=1.51  loss=47341.17 active=78224 feature_norm=301.60\n",
      "Iter 106 time=1.51  loss=47301.20 active=78089 feature_norm=301.71\n",
      "Iter 107 time=1.51  loss=47269.19 active=77987 feature_norm=301.84\n",
      "Iter 108 time=1.51  loss=47232.60 active=77972 feature_norm=301.92\n",
      "Iter 109 time=1.51  loss=47204.23 active=77879 feature_norm=302.02\n",
      "Iter 110 time=1.51  loss=47170.41 active=77837 feature_norm=302.09\n",
      "Iter 111 time=1.51  loss=47147.65 active=77712 feature_norm=302.18\n",
      "Iter 112 time=1.51  loss=47119.09 active=77671 feature_norm=302.26\n",
      "Iter 113 time=1.51  loss=47092.63 active=77609 feature_norm=302.38\n",
      "Iter 114 time=1.52  loss=47068.46 active=77577 feature_norm=302.45\n",
      "Iter 115 time=1.51  loss=47048.82 active=77500 feature_norm=302.53\n",
      "Iter 116 time=1.51  loss=47028.85 active=77418 feature_norm=302.59\n",
      "Iter 117 time=1.51  loss=47009.30 active=77346 feature_norm=302.70\n",
      "Iter 118 time=1.51  loss=46987.96 active=77291 feature_norm=302.75\n",
      "Iter 119 time=1.50  loss=46970.60 active=77225 feature_norm=302.83\n",
      "Iter 120 time=1.51  loss=46951.33 active=77190 feature_norm=302.86\n",
      "Iter 121 time=1.51  loss=46934.06 active=77072 feature_norm=302.93\n",
      "Iter 122 time=1.51  loss=46915.97 active=76983 feature_norm=302.95\n",
      "Iter 123 time=1.51  loss=46896.76 active=76919 feature_norm=303.04\n",
      "Iter 124 time=1.51  loss=46880.34 active=76860 feature_norm=303.07\n",
      "Iter 125 time=1.51  loss=46863.41 active=76809 feature_norm=303.13\n",
      "Iter 126 time=1.51  loss=46848.35 active=76757 feature_norm=303.14\n",
      "Iter 127 time=1.51  loss=46832.27 active=76704 feature_norm=303.18\n",
      "Iter 128 time=1.51  loss=46817.28 active=76626 feature_norm=303.17\n",
      "Iter 129 time=1.51  loss=46800.58 active=76582 feature_norm=303.21\n",
      "Iter 130 time=1.51  loss=46784.09 active=76555 feature_norm=303.19\n",
      "Iter 131 time=1.51  loss=46767.86 active=76527 feature_norm=303.23\n",
      "Iter 132 time=1.51  loss=46752.55 active=76505 feature_norm=303.22\n",
      "Iter 133 time=1.51  loss=46740.78 active=76435 feature_norm=303.28\n",
      "Iter 134 time=1.51  loss=46727.42 active=76394 feature_norm=303.30\n",
      "Iter 135 time=1.51  loss=46716.22 active=76354 feature_norm=303.35\n",
      "Iter 136 time=1.51  loss=46705.46 active=76321 feature_norm=303.37\n",
      "Iter 137 time=1.51  loss=46695.24 active=76302 feature_norm=303.42\n",
      "Iter 138 time=1.51  loss=46683.48 active=76236 feature_norm=303.45\n",
      "Iter 139 time=1.51  loss=46672.44 active=76231 feature_norm=303.49\n",
      "Iter 140 time=1.51  loss=46661.77 active=76175 feature_norm=303.52\n",
      "Iter 141 time=1.51  loss=46650.23 active=76135 feature_norm=303.57\n",
      "Iter 142 time=1.51  loss=46639.29 active=76141 feature_norm=303.58\n",
      "Iter 143 time=1.51  loss=46631.04 active=76108 feature_norm=303.62\n",
      "Iter 144 time=1.52  loss=46620.76 active=76072 feature_norm=303.64\n",
      "Iter 145 time=1.52  loss=46611.57 active=76044 feature_norm=303.68\n",
      "Iter 146 time=1.51  loss=46602.09 active=76022 feature_norm=303.69\n",
      "Iter 147 time=1.52  loss=46594.12 active=75962 feature_norm=303.72\n",
      "Iter 148 time=1.51  loss=46586.44 active=75937 feature_norm=303.74\n",
      "Iter 149 time=1.51  loss=46577.15 active=75879 feature_norm=303.79\n",
      "Iter 150 time=1.50  loss=46569.18 active=75857 feature_norm=303.81\n",
      "Iter 151 time=1.51  loss=46560.35 active=75860 feature_norm=303.85\n",
      "Iter 152 time=1.51  loss=46552.41 active=75840 feature_norm=303.87\n",
      "Iter 153 time=1.51  loss=46543.75 active=75800 feature_norm=303.91\n",
      "Iter 154 time=1.51  loss=46536.36 active=75765 feature_norm=303.93\n",
      "Iter 155 time=1.51  loss=46526.47 active=75757 feature_norm=303.97\n",
      "Iter 156 time=1.51  loss=46519.07 active=75728 feature_norm=304.00\n",
      "Iter 157 time=1.52  loss=46510.09 active=75721 feature_norm=304.05\n",
      "Iter 158 time=1.51  loss=46503.32 active=75698 feature_norm=304.07\n",
      "Iter 159 time=1.51  loss=46494.42 active=75657 feature_norm=304.11\n",
      "Iter 160 time=1.51  loss=46487.86 active=75633 feature_norm=304.14\n",
      "Iter 161 time=1.51  loss=46479.47 active=75607 feature_norm=304.18\n",
      "Iter 162 time=1.51  loss=46473.86 active=75596 feature_norm=304.20\n",
      "Iter 163 time=1.51  loss=46464.41 active=75582 feature_norm=304.24\n",
      "Iter 164 time=1.51  loss=46457.13 active=75569 feature_norm=304.25\n",
      "Iter 165 time=1.51  loss=46449.18 active=75552 feature_norm=304.29\n",
      "Iter 166 time=1.51  loss=46441.78 active=75516 feature_norm=304.30\n",
      "Iter 167 time=1.51  loss=46433.24 active=75502 feature_norm=304.33\n",
      "Iter 168 time=1.51  loss=46426.22 active=75488 feature_norm=304.34\n",
      "Iter 169 time=1.51  loss=46417.30 active=75479 feature_norm=304.37\n",
      "Iter 170 time=1.51  loss=46410.40 active=75463 feature_norm=304.37\n",
      "Iter 171 time=1.51  loss=46402.42 active=75430 feature_norm=304.39\n",
      "Iter 172 time=1.51  loss=46395.66 active=75389 feature_norm=304.39\n",
      "Iter 173 time=1.51  loss=46387.58 active=75375 feature_norm=304.41\n",
      "Iter 174 time=1.51  loss=46381.07 active=75358 feature_norm=304.40\n",
      "Iter 175 time=1.51  loss=46373.25 active=75313 feature_norm=304.41\n",
      "Iter 176 time=1.51  loss=46367.50 active=75284 feature_norm=304.41\n",
      "Iter 177 time=1.50  loss=46359.31 active=75299 feature_norm=304.43\n",
      "Iter 178 time=1.51  loss=46353.40 active=75290 feature_norm=304.42\n",
      "Iter 179 time=1.51  loss=46345.88 active=75289 feature_norm=304.44\n",
      "Iter 180 time=1.51  loss=46340.31 active=75257 feature_norm=304.43\n",
      "Iter 181 time=1.51  loss=46333.87 active=75246 feature_norm=304.45\n",
      "Iter 182 time=1.51  loss=46328.44 active=75215 feature_norm=304.45\n",
      "Iter 183 time=1.50  loss=46322.05 active=75176 feature_norm=304.47\n",
      "Iter 184 time=1.51  loss=46316.43 active=75150 feature_norm=304.47\n",
      "Iter 185 time=1.50  loss=46310.12 active=75132 feature_norm=304.48\n",
      "Iter 186 time=1.51  loss=46304.79 active=75080 feature_norm=304.48\n",
      "Iter 187 time=1.51  loss=46298.71 active=75039 feature_norm=304.49\n",
      "Iter 188 time=1.51  loss=46292.98 active=75016 feature_norm=304.50\n",
      "Iter 189 time=1.51  loss=46286.94 active=74964 feature_norm=304.51\n",
      "Iter 190 time=1.51  loss=46281.26 active=74929 feature_norm=304.51\n",
      "Iter 191 time=1.51  loss=46275.42 active=74910 feature_norm=304.53\n",
      "Iter 192 time=1.51  loss=46269.44 active=74881 feature_norm=304.53\n",
      "Iter 193 time=1.51  loss=46264.16 active=74837 feature_norm=304.54\n",
      "Iter 194 time=1.51  loss=46258.19 active=74792 feature_norm=304.54\n",
      "Iter 195 time=1.50  loss=46252.32 active=74735 feature_norm=304.55\n",
      "Iter 196 time=1.52  loss=46245.67 active=74710 feature_norm=304.55\n",
      "Iter 197 time=1.51  loss=46239.10 active=74715 feature_norm=304.56\n",
      "Iter 198 time=1.51  loss=46232.59 active=74690 feature_norm=304.56\n",
      "Iter 199 time=1.51  loss=46225.88 active=74635 feature_norm=304.57\n",
      "Iter 200 time=1.51  loss=46219.31 active=74596 feature_norm=304.57\n",
      "Iter 201 time=1.51  loss=46212.51 active=74564 feature_norm=304.58\n",
      "Iter 202 time=1.51  loss=46205.14 active=74528 feature_norm=304.57\n",
      "Iter 203 time=1.51  loss=46197.93 active=74499 feature_norm=304.56\n",
      "Iter 204 time=1.50  loss=46190.25 active=74464 feature_norm=304.54\n",
      "Iter 205 time=1.50  loss=46183.40 active=74433 feature_norm=304.54\n",
      "Iter 206 time=1.52  loss=46176.37 active=74387 feature_norm=304.53\n",
      "Iter 207 time=1.52  loss=46169.26 active=74361 feature_norm=304.51\n",
      "Iter 208 time=1.52  loss=46160.52 active=74250 feature_norm=304.49\n",
      "Iter 209 time=1.52  loss=46154.45 active=74159 feature_norm=304.48\n",
      "Iter 210 time=1.52  loss=46148.58 active=74135 feature_norm=304.46\n",
      "Iter 211 time=1.52  loss=46142.59 active=74009 feature_norm=304.45\n",
      "Iter 212 time=1.52  loss=46135.75 active=73756 feature_norm=304.42\n",
      "Iter 213 time=1.53  loss=46129.27 active=73739 feature_norm=304.39\n",
      "Iter 214 time=1.50  loss=46124.95 active=73711 feature_norm=304.38\n",
      "Iter 215 time=1.50  loss=46119.27 active=73623 feature_norm=304.35\n",
      "Iter 216 time=1.50  loss=46112.93 active=73468 feature_norm=304.29\n",
      "Iter 217 time=1.50  loss=46107.96 active=73482 feature_norm=304.26\n",
      "Iter 218 time=1.49  loss=46103.05 active=73439 feature_norm=304.22\n",
      "Iter 219 time=1.49  loss=46096.11 active=73267 feature_norm=304.16\n",
      "Iter 220 time=1.49  loss=46091.35 active=73228 feature_norm=304.12\n",
      "Iter 221 time=1.50  loss=46086.59 active=73203 feature_norm=304.09\n",
      "Iter 222 time=1.49  loss=46081.85 active=73161 feature_norm=304.06\n",
      "Iter 223 time=1.49  loss=46076.86 active=73048 feature_norm=304.04\n",
      "Iter 224 time=1.49  loss=46071.91 active=73002 feature_norm=304.00\n",
      "Iter 225 time=1.49  loss=46067.58 active=73001 feature_norm=303.98\n",
      "Iter 226 time=1.49  loss=46062.61 active=72943 feature_norm=303.97\n",
      "Iter 227 time=1.49  loss=46057.69 active=72891 feature_norm=303.95\n",
      "Iter 228 time=1.49  loss=46054.50 active=72853 feature_norm=303.93\n",
      "Iter 229 time=1.49  loss=46049.91 active=72847 feature_norm=303.92\n",
      "Iter 230 time=1.49  loss=46047.40 active=72842 feature_norm=303.91\n",
      "Iter 231 time=1.50  loss=46042.69 active=72849 feature_norm=303.89\n",
      "Iter 232 time=1.50  loss=46039.55 active=72795 feature_norm=303.88\n",
      "Iter 233 time=1.49  loss=46035.60 active=72803 feature_norm=303.87\n",
      "Iter 234 time=1.49  loss=46032.36 active=72797 feature_norm=303.87\n",
      "Iter 235 time=1.49  loss=46029.24 active=72807 feature_norm=303.86\n",
      "Iter 236 time=1.49  loss=46026.21 active=72783 feature_norm=303.86\n",
      "Iter 237 time=1.49  loss=46023.40 active=72756 feature_norm=303.84\n",
      "Iter 238 time=1.49  loss=46020.32 active=72707 feature_norm=303.85\n",
      "Iter 239 time=1.49  loss=46017.59 active=72685 feature_norm=303.83\n",
      "Iter 240 time=1.50  loss=46014.78 active=72674 feature_norm=303.83\n",
      "Iter 241 time=1.49  loss=46012.34 active=72652 feature_norm=303.82\n",
      "Iter 242 time=1.50  loss=46009.91 active=72630 feature_norm=303.82\n",
      "Iter 243 time=1.49  loss=46007.78 active=72614 feature_norm=303.80\n",
      "Iter 244 time=1.49  loss=46005.58 active=72596 feature_norm=303.81\n",
      "Iter 245 time=1.49  loss=46003.45 active=72579 feature_norm=303.79\n",
      "Iter 246 time=1.50  loss=46001.43 active=72568 feature_norm=303.80\n",
      "Iter 247 time=1.49  loss=45999.38 active=72545 feature_norm=303.79\n",
      "Iter 248 time=1.51  loss=45997.48 active=72516 feature_norm=303.80\n",
      "Iter 249 time=1.49  loss=45995.47 active=72508 feature_norm=303.78\n",
      "Iter 250 time=1.50  loss=45993.51 active=72509 feature_norm=303.79\n",
      "Iter 251 time=1.49  loss=45991.74 active=72499 feature_norm=303.79\n",
      "Iter 252 time=1.50  loss=45990.01 active=72494 feature_norm=303.80\n",
      "Iter 253 time=1.49  loss=45988.32 active=72482 feature_norm=303.79\n",
      "Iter 254 time=1.50  loss=45986.72 active=72466 feature_norm=303.80\n",
      "Iter 255 time=1.49  loss=45985.17 active=72456 feature_norm=303.80\n",
      "Iter 256 time=1.50  loss=45983.55 active=72444 feature_norm=303.81\n",
      "Iter 257 time=1.49  loss=45981.94 active=72448 feature_norm=303.81\n",
      "Iter 258 time=1.49  loss=45980.40 active=72446 feature_norm=303.82\n",
      "Iter 259 time=1.49  loss=45979.14 active=72447 feature_norm=303.82\n",
      "Iter 260 time=1.49  loss=45977.69 active=72449 feature_norm=303.83\n",
      "Iter 261 time=1.50  loss=45976.37 active=72438 feature_norm=303.82\n",
      "Iter 262 time=1.49  loss=45975.12 active=72421 feature_norm=303.83\n",
      "Iter 263 time=1.50  loss=45973.92 active=72420 feature_norm=303.83\n",
      "Iter 264 time=1.49  loss=45972.46 active=72423 feature_norm=303.84\n",
      "Iter 265 time=1.49  loss=45971.06 active=72420 feature_norm=303.83\n",
      "Iter 266 time=1.49  loss=45969.86 active=72420 feature_norm=303.84\n",
      "Iter 267 time=1.50  loss=45968.66 active=72404 feature_norm=303.84\n",
      "Iter 268 time=1.49  loss=45967.46 active=72408 feature_norm=303.85\n",
      "Iter 269 time=1.49  loss=45966.39 active=72399 feature_norm=303.85\n",
      "Iter 270 time=1.49  loss=45965.16 active=72376 feature_norm=303.86\n",
      "Iter 271 time=1.49  loss=45964.26 active=72372 feature_norm=303.86\n",
      "Iter 272 time=1.50  loss=45963.02 active=72366 feature_norm=303.87\n",
      "Iter 273 time=1.50  loss=45962.04 active=72354 feature_norm=303.87\n",
      "Iter 274 time=1.49  loss=45961.06 active=72346 feature_norm=303.87\n",
      "Iter 275 time=1.50  loss=45960.19 active=72337 feature_norm=303.87\n",
      "Iter 276 time=1.49  loss=45959.09 active=72315 feature_norm=303.88\n",
      "Iter 277 time=1.49  loss=45958.13 active=72309 feature_norm=303.88\n",
      "Iter 278 time=1.50  loss=45957.14 active=72313 feature_norm=303.89\n",
      "Iter 279 time=1.50  loss=45956.43 active=72312 feature_norm=303.89\n",
      "Iter 280 time=1.49  loss=45955.16 active=72310 feature_norm=303.90\n",
      "Iter 281 time=1.49  loss=45954.31 active=72305 feature_norm=303.89\n",
      "Iter 282 time=1.49  loss=45953.39 active=72289 feature_norm=303.90\n",
      "Iter 283 time=1.51  loss=45952.81 active=72286 feature_norm=303.90\n",
      "Iter 284 time=1.50  loss=45951.55 active=72285 feature_norm=303.90\n",
      "Iter 285 time=1.49  loss=45950.88 active=72281 feature_norm=303.90\n",
      "Iter 286 time=1.50  loss=45949.93 active=72281 feature_norm=303.91\n",
      "Iter 287 time=1.50  loss=45949.39 active=72279 feature_norm=303.91\n",
      "Iter 288 time=1.50  loss=45948.24 active=72274 feature_norm=303.92\n",
      "Iter 289 time=1.49  loss=45947.62 active=72266 feature_norm=303.92\n",
      "Iter 290 time=1.49  loss=45946.53 active=72273 feature_norm=303.93\n",
      "Iter 291 time=1.49  loss=45946.41 active=72280 feature_norm=303.93\n",
      "Iter 292 time=1.50  loss=45944.88 active=72273 feature_norm=303.94\n",
      "Iter 293 time=1.50  loss=45944.42 active=72268 feature_norm=303.94\n",
      "Iter 294 time=1.50  loss=45943.28 active=72282 feature_norm=303.95\n",
      "Iter 295 time=1.49  loss=45943.13 active=72269 feature_norm=303.95\n",
      "Iter 296 time=1.50  loss=45941.66 active=72264 feature_norm=303.96\n",
      "Iter 297 time=1.49  loss=45941.33 active=72252 feature_norm=303.96\n",
      "Iter 298 time=1.49  loss=45940.22 active=72244 feature_norm=303.97\n",
      "Iter 299 time=1.49  loss=45940.09 active=72242 feature_norm=303.97\n",
      "Iter 300 time=1.50  loss=45938.67 active=72234 feature_norm=303.98\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 474.427\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 72234 (183073)\n",
      "Number of active attributes: 39315 (124813)\n",
      "Number of active labels: 17 (17)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.027\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=300,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=300, \n",
    "    all_possible_transitions=True,\n",
    "    verbose=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-gpe',\n",
       " 'B-tim',\n",
       " 'B-per',\n",
       " 'I-per',\n",
       " 'B-geo',\n",
       " 'B-org',\n",
       " 'I-org',\n",
       " 'I-geo',\n",
       " 'I-tim',\n",
       " 'I-gpe',\n",
       " 'B-nat',\n",
       " 'B-art',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'I-art',\n",
       " 'I-nat']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84741542204009912"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art      0.463     0.152     0.229       125\n",
      "      I-art      0.500     0.231     0.316       104\n",
      "      B-eve      0.583     0.389     0.467        90\n",
      "      I-eve      0.467     0.189     0.269        74\n",
      "      B-geo      0.858     0.906     0.881     12080\n",
      "      I-geo      0.823     0.796     0.809      2428\n",
      "      B-gpe      0.967     0.933     0.949      4883\n",
      "      I-gpe      0.868     0.623     0.725        53\n",
      "      B-nat      0.659     0.453     0.537        64\n",
      "      I-nat      0.688     0.524     0.595        21\n",
      "      B-org      0.807     0.725     0.764      6653\n",
      "      I-org      0.788     0.804     0.796      5502\n",
      "      B-per      0.852     0.813     0.832      5441\n",
      "      I-per      0.847     0.886     0.866      5550\n",
      "      B-tim      0.923     0.881     0.902      6580\n",
      "      I-tim      0.827     0.761     0.792      2076\n",
      "\n",
      "avg / total      0.855     0.842     0.847     51724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-art  -> I-art   7.799578\n",
      "B-nat  -> I-nat   6.688903\n",
      "I-art  -> I-art   6.196308\n",
      "I-gpe  -> I-gpe   6.021471\n",
      "B-eve  -> I-eve   5.996310\n",
      "I-eve  -> I-eve   5.820601\n",
      "I-nat  -> I-nat   5.469920\n",
      "B-per  -> I-per   4.951632\n",
      "B-geo  -> I-geo   4.410065\n",
      "B-gpe  -> I-gpe   4.378625\n",
      "I-tim  -> I-tim   4.315825\n",
      "B-tim  -> I-tim   3.960423\n",
      "B-org  -> I-org   3.893750\n",
      "O      -> O       3.864032\n",
      "I-geo  -> I-geo   3.842113\n",
      "I-org  -> I-org   3.631559\n",
      "I-per  -> I-per   3.305204\n",
      "O      -> B-per   1.606649\n",
      "O      -> B-tim   1.394839\n",
      "O      -> B-art   1.287362\n",
      "\n",
      "Top unlikely transitions:\n",
      "B-gpe  -> I-geo   -4.545596\n",
      "B-org  -> I-per   -4.600611\n",
      "I-org  -> I-geo   -4.640364\n",
      "B-tim  -> I-org   -4.657284\n",
      "I-org  -> I-tim   -4.818423\n",
      "I-tim  -> B-tim   -5.066340\n",
      "B-geo  -> B-geo   -5.222233\n",
      "I-org  -> I-per   -5.398635\n",
      "B-org  -> B-org   -5.678400\n",
      "B-geo  -> I-org   -5.714928\n",
      "O      -> I-per   -5.740573\n",
      "B-gpe  -> I-org   -5.893992\n",
      "I-per  -> B-per   -6.216838\n",
      "B-gpe  -> B-gpe   -6.245837\n",
      "B-tim  -> B-tim   -6.377297\n",
      "I-org  -> B-org   -6.414465\n",
      "O      -> I-tim   -7.124532\n",
      "O      -> I-org   -7.672739\n",
      "O      -> I-geo   -8.743801\n",
      "B-per  -> B-per   -9.755864\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "13.899187 B-org    word.lower():al-qaida\n",
      "11.673425 O        word.lower():a\n",
      "11.398022 B-tim    word.lower():monday\n",
      "11.393706 B-tim    word.lower():tuesday\n",
      "11.391254 B-tim    word.lower():wednesday\n",
      "11.356989 B-tim    word.lower():thursday\n",
      "11.356911 O        word.lower():i\n",
      "11.193764 B-tim    word.lower():friday\n",
      "10.944232 B-tim    word.lower():sunday\n",
      "10.800134 B-tim    word.lower():saturday\n",
      "10.349381 O        word.lower():h5n1\n",
      "9.661956 B-gpe    word.lower():nepal\n",
      "9.186212 B-gpe    word.lower():israeli\n",
      "9.175654 B-gpe    word.lower():arabs\n",
      "9.162647 B-gpe    word.lower():iraqi\n",
      "9.134573 B-gpe    word.lower():afghan\n",
      "8.997418 B-per    word.lower():vice\n",
      "8.815316 B-per    word.lower():al-zarqawi\n",
      "8.716122 O        word.lower():last\n",
      "8.696344 B-gpe    word.lower():iranian\n",
      "8.629663 B-gpe    word.lower():niger\n",
      "8.415910 O        BOS\n",
      "8.340910 B-tim    word.lower():today\n",
      "8.111946 B-tim    word.lower():1990s\n",
      "8.070171 B-org    word.lower():taleban\n",
      "8.005969 B-art    word.lower():spaceshipone\n",
      "7.949322 B-tim    word.lower():december\n",
      "7.948263 B-per    word.lower():mr.\n",
      "7.921513 B-nat    word.lower():marburg\n",
      "7.869917 B-tim    word.lower():february\n",
      "\n",
      "Top negative:\n",
      "-3.416459 O        word.lower():multi-candidate\n",
      "-3.466869 O        word.lower():mid-august\n",
      "-3.481107 O        word.lower():multi-party\n",
      "-3.494293 O        word.lower():three-month\n",
      "-3.509681 O        word.lower():two-year\n",
      "-3.580475 O        word.lower():today\n",
      "-3.606300 O        +1:word.lower():accountable\n",
      "-3.608957 O        +1:word.lower():year\n",
      "-3.652266 O        word.lower():morning\n",
      "-3.656007 O        word.lower():19th\n",
      "-3.658547 O        word.lower():summer\n",
      "-3.732595 O        word.lower():four-day\n",
      "-3.739995 O        word.lower():10th\n",
      "-3.763535 O        word.lower():one-fifth\n",
      "-3.782210 O        word.lower():mid-september\n",
      "-3.783369 O        word.lower():two-day\n",
      "-3.827566 I-per    -1:word.lower():sri\n",
      "-3.882340 B-geo    word.isdigit()\n",
      "-3.883540 O        word.lower():al-qaeda\n",
      "-3.889681 O        word.lower():three-day\n",
      "-4.029674 O        -1:word.lower():cote\n",
      "-4.064771 O        word.lower():16th\n",
      "-4.263574 O        word.lower():one-day\n",
      "-4.331444 I-org    word.lower():secretary\n",
      "-4.336709 O        word.lower():one-year\n",
      "-4.526532 O        word.lower():lashkar-e-jhangvi\n",
      "-4.841419 O        word.lower():three-year\n",
      "-4.848936 O        word.isupper()\n",
      "-5.109195 O        word.lower():afternoon\n",
      "-6.225637 O        word.istitle()\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gzip.open('models/ner/crf.pkl.gz', mode='wb') as fp:\n",
    "    pickle.dump(crf, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from algorithms.ner_crf import NerCrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeler = NerCrf('models/ner/crf.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = (\n",
    "    'Mr. Puigdemont has appeared in public in Brussels with several colleagues'\n",
    "    'after declaring independence from Spain on October 27.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mr', 'B-per'),\n",
       " ('Puigdemont', 'I-per'),\n",
       " ('has', 'O'),\n",
       " ('appeared', 'O'),\n",
       " ('in', 'O'),\n",
       " ('public', 'O'),\n",
       " ('in', 'O'),\n",
       " ('Brussels', 'B-geo'),\n",
       " ('with', 'O'),\n",
       " ('several', 'O'),\n",
       " ('colleaguesafter', 'O'),\n",
       " ('declaring', 'O'),\n",
       " ('independence', 'O'),\n",
       " ('from', 'O'),\n",
       " ('Spain', 'B-geo'),\n",
       " ('on', 'O'),\n",
       " ('October', 'B-tim'),\n",
       " ('27', 'I-tim')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeler.predict(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "notify_time": "30",
  "toc": {
   "colors": {
    "hover_highlight": "#597be5",
    "running_highlight": "#FF0000",
    "selected_highlight": "#4bdb3b"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "170px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "632px",
    "left": "0px",
    "right": "1388.84px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
